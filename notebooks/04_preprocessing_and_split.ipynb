{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8874aa1-6e73-4411-8347-3051b94c5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d82cac-ecb3-4547-9d6a-cf63b14c532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (2200, 8)\n",
      "\n",
      "Class distribution:\n",
      " label\n",
      "rice           100\n",
      "maize          100\n",
      "chickpea       100\n",
      "kidneybeans    100\n",
      "pigeonpeas     100\n",
      "mothbeans      100\n",
      "mungbean       100\n",
      "blackgram      100\n",
      "lentil         100\n",
      "pomegranate    100\n",
      "banana         100\n",
      "mango          100\n",
      "grapes         100\n",
      "watermelon     100\n",
      "muskmelon      100\n",
      "apple          100\n",
      "orange         100\n",
      "papaya         100\n",
      "coconut        100\n",
      "cotton         100\n",
      "jute           100\n",
      "coffee         100\n",
      "Name: count, dtype: int64\n",
      "Encoded classes example: {'apple': np.int64(0), 'banana': np.int64(1), 'blackgram': np.int64(2), 'chickpea': np.int64(3), 'coconut': np.int64(4), 'coffee': np.int64(5), 'cotton': np.int64(6), 'grapes': np.int64(7), 'jute': np.int64(8), 'kidneybeans': np.int64(9), 'lentil': np.int64(10), 'maize': np.int64(11), 'mango': np.int64(12), 'mothbeans': np.int64(13), 'mungbean': np.int64(14), 'muskmelon': np.int64(15), 'orange': np.int64(16), 'papaya': np.int64(17), 'pigeonpeas': np.int64(18), 'pomegranate': np.int64(19), 'rice': np.int64(20), 'watermelon': np.int64(21)}\n",
      "\n",
      "Scaled features sample:\n",
      "          N         P         K  temperature  humidity        ph  rainfall\n",
      "0  1.068797 -0.344551 -0.101688    -0.935587  0.472666  0.043302  1.810361\n",
      "1  0.933329  0.140616 -0.141185    -0.759646  0.397051  0.734873  2.242058\n",
      "2  0.255986  0.049647 -0.081939    -0.515898  0.486954  1.771510  2.921066\n",
      "3  0.635298 -0.556811 -0.160933     0.172807  0.389805  0.660308  2.537048\n",
      "4  0.743673 -0.344551 -0.121436    -1.083647  0.454792  1.497868  2.898373\n",
      "\n",
      "Scaled stats:\n",
      "             N        P        K  temperature  humidity       ph  rainfall\n",
      "count  2200.00  2200.00  2200.00      2200.00   2200.00  2200.00   2200.00\n",
      "mean     -0.00     0.00    -0.00         0.00     -0.00    -0.00      0.00\n",
      "std       1.00     1.00     1.00         1.00      1.00     1.00      1.00\n",
      "min      -1.37    -1.47    -0.85        -3.32     -2.57    -3.83     -1.52\n",
      "25%      -0.80    -0.77    -0.56        -0.56     -0.50    -0.64     -0.71\n",
      "50%      -0.37    -0.07    -0.32        -0.00      0.40    -0.06     -0.16\n",
      "75%       0.91     0.44     0.02         0.58      0.83     0.59      0.38\n",
      "max       2.42     2.78     3.10         3.57      1.28     4.48      3.55\n",
      "\n",
      "Split sizes:\n",
      "Train: 1540 samples\n",
      "Validation: 330 samples\n",
      "Test: 330 samples\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib  # For saving preprocessors (useful for FastAPI deployment later)\n",
    "import os\n",
    "\n",
    "# Create processed data folder\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "df = pd.read_csv('../data/Crop_recommendation.csv')\n",
    "\n",
    "print(\"Original shape:\", df.shape)\n",
    "print(\"\\nClass distribution:\\n\", df['label'].value_counts())\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Encode target labels (crop names â†’ integers)\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Save the label encoder for deployment (to decode predictions back to crop names)\n",
    "joblib.dump(le, '../models/label_encoder.pkl')\n",
    "\n",
    "print(\"Encoded classes example:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Save the scaler for deployment\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "\n",
    "# Convert back to DataFrame for inspection\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "print(\"\\nScaled features sample:\")\n",
    "print(X_scaled_df.head())\n",
    "print(\"\\nScaled stats:\")\n",
    "print(X_scaled_df.describe().round(2))\n",
    "\n",
    "# Train/validation/test split (70/15/15)\n",
    "# First split train + (val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Then split temp into val and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"\\nSplit sizes:\")\n",
    "print(f\"Train: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation: {X_val.shape[0]} samples\")\n",
    "print(f\"Test: {X_test.shape[0]} samples\")\n",
    "\n",
    "pd.DataFrame(X_train, columns=X.columns).to_csv('../data/processed/X_train.csv', index=False)\n",
    "pd.DataFrame(X_val, columns=X.columns).to_csv('../data/processed/X_val.csv', index=False)\n",
    "pd.DataFrame(X_test, columns=X.columns).to_csv('../data/processed/X_test.csv', index=False)\n",
    "pd.DataFrame(y_train, columns=['label_encoded']).to_csv('../data/processed/y_train.csv', index=False)\n",
    "pd.DataFrame(y_val, columns=['label_encoded']).to_csv('../data/processed/y_val.csv', index=False)\n",
    "pd.DataFrame(y_test, columns=['label_encoded']).to_csv('../data/processed/y_test.csv', index=False)\n",
    "\n",
    "# save original y (crop names) for val/test for analysis\n",
    "pd.DataFrame(y_train_original := le.inverse_transform(y_train), columns=['crop']).to_csv('../data/processed/y_train_names.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e2562-8242-4980-80a3-196b4a3b430e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
